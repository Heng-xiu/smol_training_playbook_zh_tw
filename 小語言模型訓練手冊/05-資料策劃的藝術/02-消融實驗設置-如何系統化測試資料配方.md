### [消融實驗設置:如何系統化測試資料配方](https://huggingfacetb-smol-training-playbook.hf.space/#ablation-setup-how-to-systematically-test-data-recipes)

在測試資料混合時,我們的方法類似於我們執行架構消融實驗的方式,有一個不同:我們嘗試在目標模型規模上執行它們。小型和大型模型具有不同的容量,例如非常小的模型可能難以處理多種語言,而較大的模型可以吸收它們而不在其他地方犧牲效能。因此,在太小的規模上執行資料消融實驗有可能對最佳混合得出錯誤結論的風險。

對於 SmolLM3,我們直接在 3B 模型上執行主要資料消融實驗,使用 50B 和 100B tokens 的較短訓練執行。我們還使用了另一種類型的消融實驗設置:**退火實驗**。我們不是用不同的混合從頭開始訓練,而是從主執行中取一個中間檢查點(例如在 7T tokens 處)並用修改後的資料組成繼續訓練。這種方法允許我們測試用於進行多階段訓練(即在訓練中期改變訓練混合)的資料混合變更,並在最近的工作中使用,如 SmolLM2、Llama3 和 Olmo2。對於評估,我們擴展了我們的基準測試套件,除了我們的標準英語評估外還包括多語言任務,確保我們可以正確評估不同語言比率之間的權衡。

_從頭開始消融實驗_
_0 → 100B Tokens_
_學習率_

_退火消融實驗(vs 主預訓練)_
_0 → 7.1T → 11T Tokens_
_學習率_

最近的工作提出了用於找到最佳資料比例的自動化方法,包括:

  - **DoReMi** ([Xie et al., 2023](https://arxiv.org/abs/2305.10429)):使用小型代理模型學習最小化驗證損失的領域權重
  - **Rho Loss** ([Mindermann et al., 2022](https://arxiv.org/abs/2206.07137)):根據 holdout 損失選擇單獨的訓練點,優先考慮可學習、任務相關且模型尚未學習的樣本
  - **RegMix** ([Q. Liu et al., 2025](https://arxiv.org/abs/2407.01492)):透過正則化回歸確定最佳資料混合比例,該回歸在多個評估目標和資料領域之間平衡效能

我們在過去的專案中實驗了 DoReMi 和 Rho Loss,但發現它們傾向於收斂到大致反映資料集大小自然分布的分布,本質上建議使用更多我們擁有更多的東西。雖然在理論上很吸引人,但在我們的設置中它們沒有優於仔細的手動消融實驗。最近的 SOTA 模型仍然依賴於透過系統化消融實驗和退火實驗進行手動混合調整,這是我們為 SmolLM3 採用的方法。
