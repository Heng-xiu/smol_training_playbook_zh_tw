## 從小型消融實驗開始

在我們開始訓練 LLM 之前，需要做出許多將塑造模型效能和訓練效率的決策。哪種架構最適合我們的用例？使用什麼優化器和學習率排程？混合哪些資料來源？

如何做出這些決策是一個經常被問到的問題。人們有時期望這些決策是透過深思熟慮得出的。雖然戰略思考至關重要——正如我們在[前一章節](https://huggingfacetb-smol-training-playbook.hf.space/#training-compass-why--what--how)中討論的，識別哪些架構變更值得測試——但僅僅依靠推理是不夠的。在 LLM 領域，事情並不總是符合直覺，關於什麼應該有效的假設有時在實踐中並不成立。

例如，使用看似「最高品質的資料」並不總能產生更強大的模型。以 [arXiv](https://arxiv.org/) 為例，這是人類科學知識的龐大集合。直覺上，在如此豐富的 STEM 資料上訓練應該產生更優秀的模型，對吧？實際上並非如此，尤其是對於較小的模型，它甚至可能損害效能 ([Shao et al., 2024](https://arxiv.org/abs/2402.03300))。為什麼？原因在於，雖然 arXiv 論文充滿知識，但它們高度專業化，以狹窄的學術風格撰寫，與模型最佳學習的多樣化、通用文本截然不同。

那麼，如果長時間盯著問題思考也無濟於事，我們如何知道什麼有效呢？像優秀的經驗主義者一樣，我們大量實驗！機器學習不是純數學，而實際上更像是一門實驗科學。

> 💡 從很多方面來說，機器學習類似於發現統計力學之前的熱力學：我們擁有可靠的經驗定律和設計原則，它們運作得非常好，即使更深層的理論解釋仍在浮現中。

由於這些實驗將指導我們的許多關鍵決策，正確設置它們非常重要。我們對這些實驗有兩個主要要求：

1. **速度：** 它們應該盡可能快地執行，以便我們能夠頻繁迭代。我們能執行的消融實驗越多，就能測試越多的假設。
2. **可靠性：** 它們應該提供強大的區分能力。如果我們觀察的指標無法在早期有意義地區分不同的設置，我們的消融實驗可能收穫甚微（如果它們有雜訊，我們還可能在追逐雜訊！）。更多細節請查看 [FineTasks 部落格文章](https://huggingface.co/spaces/HuggingFaceFW/blogpost-fine-tasks)。

但在設置消融實驗之前，我們需要對架構類型和模型大小做出一些基礎性選擇。這些決策——由我們的羅盤指引——影響著使用哪個訓練框架、如何分配算力預算，以及從哪個基準線開始。

對於 SmolLM3，我們選擇了 3B 參數的密集型 Llama 風格架構，因為我們的目標是小型端側模型。但正如你將在[設計模型架構章節](https://huggingfacetb-smol-training-playbook.hf.space/#designing-the-model-architecture)中看到的，MoE 或混合模型可能更適合你的用例，不同的模型大小也會帶來不同的權衡。我們稍後將深入探討這些選擇，並展示如何做出這些決策。現在，讓我們從最實際的第一步開始：選擇你的基準線。
