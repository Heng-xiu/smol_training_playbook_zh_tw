### [行業工具](https://huggingfacetb-smol-training-playbook.hf.space/#tools-of-the-trade)

每個後訓練配方背後都有一個框架和函式庫的工具箱,可以實現大規模實驗。每個框架都帶來了自己的一組支援演算法、微調方法和可擴展性功能。下表總結了主要支援領域,從監督式微調(SFT)到偏好優化(PO)和強化學習(RL):
框架 | SFT | PO | RL | Multi-modal | FullFT | LoRA | Distributed
---|---|---|---|---|---|---|---
[**TRL**](https://github.com/huggingface/trl) | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ✅
[**Axolotl**](https://github.com/axolotl-ai-cloud/axolotl) | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ✅
[**OpenInstruct**](https://github.com/allenai/open-instruct) | ✅ | ✅ | ✅ | ❌ | ✅ | ✅ | ✅
[**Unsloth**](https://github.com/unslothai/unsloth) | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ✅
[**vERL**](https://github.com/volcengine/verl) | ✅ | ❌ | ✅ | ✅ | ✅ | ✅ | ✅
[**Prime RL**](https://github.com/PrimeIntellect-ai/prime-rl) | ✅ | ❌ | ✅ | ❌ | ✅ | ✅ | ✅
[**PipelineRL**](https://github.com/ServiceNow/PipelineRL) | ❌ | ❌ | ✅ | ❌ | ✅ | ✅ | ✅
[**ART**](https://github.com/OpenPipe/ART/tree/main) | ❌ | ❌ | ✅ | ❌ | ❌ | ✅ | ❌
[**TorchForge**](https://github.com/meta-pytorch/torchforge) | ✅ | ❌ | ✅ | ❌ | ✅ | ❌ | ✅
[**NemoRL**](https://github.com/NVIDIA-NeMo/RL) | ✅ | ✅ | ✅ | ❌ | ✅ | ❌ | ✅
[**OpenRLHF**](https://github.com/OpenRLHF/OpenRLHF) | ✅ | ✅ | ✅ | ❌ | ✅ | ✅ | ✅

這裡 _FullFT_ 指的是**完全微調**,其中所有模型參數在訓練期間都會更新。_LoRA_ 代表 **Low-Rank Adaptation**,一種參數高效的方法,只更新小型低秩矩陣,同時保持基礎模型凍結。_Multi-modal_ 指的是是否支援在文本之外的模態(例如影像)上訓練,_Distributed_ 表示是否可以在多個 GPU 上訓練模型。
在 Hugging Face,我們開發和維護 TRL,因此它是我們的首選框架,也是我們用於後訓練 SmolLM3 的框架。
Fork 你的框架
鑑於該領域的快速發展,我們發現在 TRL 的內部 fork 上執行實驗非常有效。這使我們能夠非常快速地新增新功能,這些功能後來被上游到主函式庫。如果你熟悉使用框架的內部,採用類似的工作流程可以成為快速迭代的強大方法。

#### [為什麼要費心使用框架?](https://huggingfacetb-smol-training-playbook.hf.space/#why-bother-with-frameworks-at-all)

有一類研究人員喜歡抱怨訓練框架的使用,而是主張你應該從頭開始實作一切,一直如此。這裡的隱含主張是「真正的」理解只來自重新實作每個 RL 演算法、手動編碼每個分散式訓練原語,或拼湊一次性評估工具。
但這種立場忽略了現代研究和生產的現實。以 RL 為例。像 PPO 和 GRPO 這樣的演算法以正確實作而聞名是棘手的 ([Huang et al., 2024](https://arxiv.org/abs/2403.17031)),正規化或 KL 懲罰中的微小錯誤可能導致數天的計算和精力浪費。
同樣,儘管編寫某個演算法的單檔案實作很誘人,但同一個腳本能否從 1B 擴展到 100B+ 參數?
框架的存在正是因為基礎知識已經被充分理解,無休止地重新發明它們是對時間的糟糕使用。這並不是說低層級修補沒有價值。從頭實作 PPO 一次是一個很好的學習練習。在沒有框架的情況下編寫一個玩具 transformer 可以教你注意力如何真正工作。但在大多數情況下,只需選擇一個你喜歡的框架並為你的目的駭客它。
既然這個咆哮已經結束了,讓我們看看我們通常從哪裡開始我們的訓練執行。
