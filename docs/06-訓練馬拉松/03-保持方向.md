### [保持方向](https://huggingfacetb-smol-training-playbook.hf.space/#staying-the-course)

如前一節所示,從消融實驗擴展到完整預訓練不僅僅是「即插即用」。它帶來了意外的挑戰,但我們成功地識別並解決了每個問題。本節涵蓋大規模訓練執行的基本監控設置和考慮因素。我們將解決關鍵問題:在遇到問題後何時應該重新開始訓練?如何處理在執行深入時浮現的問題?哪些指標真正重要?你應該在整個訓練過程中保持固定的資料混合嗎?

#### [訓練監控:超越損失曲線](https://huggingfacetb-smol-training-playbook.hf.space/#training-monitoring-beyond-loss-curves)

我們捕獲 tensor-parallelism 錯誤的原因不是損失曲線(看起來很好),而是下游評估落後於預期的事實。此外,擁有來自 SmolLM2 中間檢查點的評估至關重要:它們給了我們一個健全性檢查,表明 3B 模型早期沒有在正確的軌道上。因此,如果你正在訓練大型模型,盡早開始執行下游評估,如果你正在與開源模型進行比較,詢問作者是否可以提供中間檢查點,這些可能是寶貴的參考點。
在基礎設施方面,最重要的指標是輸送量,以每秒 tokens 數衡量。對於 SmolLM3,我們期望在整個執行中穩定的輸送量在 13,500–14,000 tokens/sec 之間,任何持續的偏差都是危險訊號。但僅輸送量是不夠的:你還需要持續的硬體健康監控來預測和檢測硬體故障。我們追蹤的一些關鍵指標包括:GPU 溫度、記憶體使用和計算利用率。我們將它們記錄到 Grafana 儀表板中,並為硬體異常設定即時 Slack 警報。

#### [修復並重新開始 vs 即時修復](https://huggingfacetb-smol-training-playbook.hf.space/#fix-and-restart-vs-fix-on-the-fly)

鑑於我們在 1T tokens 後重新開始執行,一個重要的問題出現了:當出現問題時,你總是需要重新開始嗎?答案取決於問題的嚴重性和根本原因。
在我們的情況下,TP 種子錯誤意味著我們從錯誤的起點開始,我們一半的權重沒有正確初始化。該模型顯示出與 SmolLM2 類似的效能,並在類似的點達到平台期,這意味著我們可能最終會得到一個效能相同但訓練成本幾乎是兩倍的模型。重新開始是有道理的。然而,許多問題可以在執行中期進行路線修正,以避免浪費計算。最常見的問題涉及_損失峰值_,那些訓練損失的突然跳躍,可以發出小問題或發散的訊號。
正如 [Stas Bekman](https://media.istockphoto.com/id/486869012/fr/photo/ch%C3%A8vre-est-%C3%A0-nous.jpg?s=612x612&w=0&k=20&c=F26PCPZiy1P3FLZS23GWhKcQ8Buqfx8StHYoX85hq-s%3D) 在 [Machine Learning Engineering Open Book](https://github.com/stas00/ml-engineering/blob/master/training/instabilities/training-loss-patterns.md) 中很好地說的那樣「訓練損失圖類似於心跳模式 — 有好的、壞的和你應該擔心的。」
損失峰值分為兩類:
  - 可恢復的峰值:這些可以快速恢復(峰值後立即)或緩慢恢復(需要更多訓練步驟才能返回峰值前的軌跡)。你通常可以繼續訓練通過這些。如果恢復非常緩慢,你可以嘗試倒回到之前的檢查點以跳過有問題的批次。
  - 不可恢復的峰值:模型要麼發散,要麼在比峰值前更差的效能上達到平台期。這些需要比簡單地倒回到之前的檢查點更重要的介入。
雖然我們不完全理解訓練不穩定性,但我們知道它們在規模上變得更頻繁。假設一個保守的架構和優化器,常見的罪魁禍首包括:
  - 高學習率:這些在訓練早期導致不穩定,可以透過降低學習率來修復。
  - 不良資料:通常是可恢復峰值的主要原因,儘管恢復可能很慢。這可能發生在訓練深入時,當模型遇到低品質資料時。
  - 資料-參數狀態互動:PaLM ([Chowdhery et al., 2022](https://arxiv.org/abs/2204.02311)) 觀察到峰值通常是由資料批次和模型參數狀態的特定組合導致的,而不僅僅是「不良資料」。從不同的檢查點在相同的有問題的批次上訓練並沒有重現峰值。
  - 不良初始化:OLMo2 ([OLMo et al., 2025](https://arxiv.org/abs/2501.00656)) 最近的工作表明,從縮放初始化切換到簡單的正態分布(mean=0, std=0.02)改善了穩定性。
  - 精度問題:雖然沒有人再使用 FP16 訓練,但 [BLOOM](https://arxiv.org/abs/2211.05100) 發現它與 BF16 相比非常不穩定。
**在峰值發生之前,建立穩定性:**
具有保守學習率和良好資料的小型模型很少峰值,但較大的模型需要主動的穩定性措施。隨著更多團隊在規模上訓練,我們已經積累了一個技術工具包,有助於防止訓練不穩定性:
資料過濾和隨機排列:到部落格的這一點,你已經注意到我們多麼經常回到資料。確保你的資料乾淨且隨機排列良好可以防止峰值。例如,OLMo2 發現移除具有重複 n-grams(1-13 token spans 的 32+ 次重複)的文件顯著減少了峰值頻率。
訓練修改:Z-loss 正則化使輸出 logits 不會增長得太大而不影響效能。並且從權重衰減中排除 embeddings 也有所幫助。
架構變更:QKNorm(在注意力之前正規化查詢和鍵投影)已被證明是有效的。OLMo2 和其他團隊發現它有助於穩定性,有趣的是,[Marin 團隊](https://wandb.ai/marin-community/marin/reports/Marin-32B-Work-In-Progress--VmlldzoxMzM1Mzk1NQ)發現它甚至可以在執行中期應用以修復發散問題。
**當峰值仍然發生時 - 損害控制:**
即使有這些預防措施,峰值仍然可能發生。以下是修復它們的一些選項:
  - **跳過有問題的批次**:倒回到峰值之前並跳過有問題的批次。這是峰值的最常見修復。Falcon 團隊 ([Almazrouei et al., 2023](https://arxiv.org/abs/2311.16867)) 跳過了 1B tokens 來解決他們的峰值,而 PaLM 團隊 ([Chowdhery et al., 2022](https://arxiv.org/abs/2204.02311)) 發現跳過峰值位置周圍的 200-500 個批次可以防止復發。
  - **收緊梯度裁剪**:暫時降低梯度範數閾值
  - **應用架構修復**,如 QKnorm,如 Marin 中所做的那樣。
我們已經走過了擴展挑戰,從輸送量下降到 TP 錯誤,從及早捕獲問題的監控實踐,以及防止和修復損失峰值的策略。讓我們透過討論多階段訓練如何增強你的模型最終效能來完成本章。
