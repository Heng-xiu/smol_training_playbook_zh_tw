### [總結預訓練](https://huggingfacetb-smol-training-playbook.hf.space/#wrapping-up-pretraining)

我們已經涵蓋了很多領域。從幫助我們決定為什麼和訓練什麼的訓練羅盤,透過策略規劃、驗證每個架構選擇的系統化消融實驗,到實際訓練馬拉松,其中在規模上出現了驚喜(輸送量神秘地崩潰、dataloader 瓶頸,以及在 1T tokens 處迫使重新開始的微妙 tensor parallelism 錯誤)。
那些精美的技術報告背後的混亂現實現在是可見的:**訓練 LLM 與架構創新和資料策劃一樣,也關乎有紀律的實驗和快速除錯。** 計劃識別值得測試的內容。消融實驗驗證每個決定。監控及早捕獲問題。當事情不可避免地出錯時,系統化的去風險告訴你確切地在哪裡尋找。
具體而言,對於 SmolLM3,這個過程交付了我們打算建立的東西:一個在 11T tokens 上訓練的 3B 模型,在數學、程式碼、多語言理解和長上下文任務上具有競爭力,處於 Qwen3 模型的 Pareto 前沿。
2.02.53.03.54.04.52.02.53.03.54.04.55.0Model Size (Billion parameters)Win Rate (%) - 12 popular LLM Benchmarksfaster / cheaperbetter
![](https://huggingfacetb-smol-training-playbook.hf.space/data/qwen-logo.svg)
Qwen3 1.7BBase
![](https://huggingfacetb-smol-training-playbook.hf.space/data/qwen-logo.svg)
Qwen2.53B
![](https://huggingfacetb-smol-training-playbook.hf.space/data/hf-logo.svg)
SmolLM3 3BBase
![](https://huggingfacetb-smol-training-playbook.hf.space/data/meta-logo.svg)
Llama3.23B
![](https://huggingfacetb-smol-training-playbook.hf.space/data/qwen-logo.svg)
Qwen3 4BBase
![](https://huggingfacetb-smol-training-playbook.hf.space/data/google-logo.svg)
Gemma3 4BBase
基礎模型評估的勝率:HellaSwag、ARC、Winogrande、CommonsenseQA、MMLU-CF、MMLU Pro CF、PIQA、OpenBookQA、GSM8K、MATH、HumanEval+、MBPP+
隨著我們的基礎模型檢查點儲存、訓練完成,以及 GPU 終於冷卻下來,我們可能會想要稱之為完成。畢竟,我們有一個很好地預測文本的模型,達到強大的基準測試分數,並展示了我們目標的能力。
還不完全。因為今天人們想要的是助理和編碼代理,而不是原始的下一個 token 預測器。
這就是後訓練的用武之地。就像預訓練一樣,現實比論文暗示的更混亂。
