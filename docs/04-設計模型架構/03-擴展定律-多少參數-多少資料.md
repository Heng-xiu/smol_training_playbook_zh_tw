### [擴展定律:多少參數,多少資料?](https://huggingfacetb-smol-training-playbook.hf.space/#scaling-laws-how-many-parameters-how-much-data)

在深度學習的早期,在語言模型(以及它們訓練的叢集)成為「大型」之前,訓練執行通常不會受到計算的嚴重約束。在訓練模型時,你只需選擇適合你硬體的最大模型和批次大小,然後訓練直到模型開始過擬合或你用完資料。然而,即使在這些早期,人們也有一種規模是有幫助的感覺 — 例如,[Hestness et al.](https://arxiv.org/abs/1712.00409) 在 2017 年提供了一組全面的結果,顯示訓練更大的模型更長時間會產生可預測的收益。

在大型語言模型時代,我們_總是_受到計算約束。為什麼?這些早期的可擴展性概念被 [Kaplan et al. 關於神經語言模型擴展定律的工作](https://arxiv.org/abs/2001.08361)正式化,其中顯示語言模型效能在許多數量級的規模上是顯著可預測的。這引發了語言模型的大小和訓練持續時間的爆炸,因為它提供了一種方法來_準確預測_從增加規模中效能會提高多少。因此,建立更好語言模型的競賽變成了在更大的計算預算下訓練更大的模型在更大量的資料上的競賽,語言模型的開發迅速變得受到計算約束。

面對計算約束時,最重要的問題是訓練更大的模型還是在更多資料上訓練。令人驚訝的是,Kaplan et al. 的擴展定律建議將更多計算分配給模型規模比以前的最佳實踐更有利 — 例如,激勵在相對適度的 token 預算(300B tokens)上訓練龐大的(175B 參數)GPT-3 模型。經過重新審查,[Hoffman et al.](https://arxiv.org/abs/2203.15556) 發現 Kaplan et al. 方法的方法論問題,最終重新導出擴展定律,建議將更多計算分配給訓練持續時間,這表明,例如,175B 參數 GPT-3 的計算最優訓練應該消耗 3.7T tokens!

這將領域從「使模型更大」轉變為「訓練它們更長時間和更好」。然而,大多數現代訓練仍然不嚴格遵循 Chinchilla 定律,因為它們有一個缺點:它們旨在預測在給定計算預算下實現最佳效能的模型大小和_訓練_持續時間,但它們未能考慮更大模型在訓練_後_更昂貴的事實。換句話說,我們實際上可能更喜歡使用給定的計算預算訓練更小的模型更長時間 — 即使這不是「計算最優」的 — 因為這將使推理成本更便宜 ([Sardana et al.](https://arxiv.org/abs/2401.00448), [de Vries](https://www.harmdevries.com/post/model-size-vs-compute-overhead/))。如果我們期望模型會看到大量推理使用(例如,因為它正在公開發布 🤗),這可能是這種情況。最近,這種「過度訓練」模型超過擴展定律建議的訓練持續時間的做法已成為標準做法,這是我們在開發 SmolLM3 時採取的方法。

雖然擴展定律為給定特定計算預算的模型大小和訓練持續時間提供建議,但選擇過度訓練意味著你必須自己決定這些因素。對於 SmolLM3,我們首先選擇了 30 億參數的目標模型大小。基於類似規模的最近模型,如 Qwen3 4B、Gemma 3 4B 和 Llama 3.2 3B,我們認為 3B 足夠大以具有有意義的能力(如推理和工具呼叫),但又足夠小以實現超快推理和高效本地使用。為了選擇訓練持續時間,我們首先注意到最近的模型已經被_極度_過度訓練 — 例如,前述的 Qwen3 系列聲稱已經訓練了 36T tokens!因此,訓練持續時間通常由可用的計算量決定。我們獲得了大約一個月的 384 個 H100,這提供了在 11 兆 tokens 上訓練的預算(假設 MFU ~30%)。

**擴展定律**

儘管有這些偏差,擴展定律仍然實際上是有價值的。它們為實驗設計提供基準線,人們經常使用 Chinchilla 最優設置來獲得消融實驗的訊號,它們幫助預測模型大小是否可以達到目標效能。正如 de Vries 在這個[部落格](https://www.harmdevries.com/post/model-size-vs-compute-overhead/)中所指出的,透過縮小模型大小,你可以達到臨界模型大小:達到給定損失所需的最小容量,低於此你開始獲得遞減回報。

現在我們已經確定了我們的模型架構、訓練設置、模型大小和訓練持續時間,我們需要準備兩個關鍵組件:將教導我們模型的資料混合,以及將可靠地訓練它的基礎設施。隨著 SmolLM3 的架構設定為 3B 參數,我們需要策劃一個資料混合,以提供強大的多語言、數學和程式碼效能,並建立足夠穩健的基礎設施來進行 11 兆 tokens 的訓練。正確掌握這些基礎至關重要,即使是最好的架構選擇也無法拯救我們免受糟糕的資料策劃或不穩定的訓練系統的影響。
